{"/docs/agent/config":{"title":"Config","data":{}},"/docs/agent/event":{"title":"Event","data":{}},"/docs/agent":{"title":"Index","data":{}},"/docs/agent/history":{"title":"History","data":{}},"/docs/backend/e2e":{"title":"E2e","data":{}},"/docs/backend":{"title":"Index","data":{}},"/docs/backend/prisma":{"title":"Prisma","data":{}},"/docs/backend/nestjs":{"title":"Nestjs","data":{}},"/docs":{"title":"Index","data":{"autobe-vibe-coding-agent-for-backend-applications#AutoBE, Vibe Coding Agent for Backend Applications":"Backend Vibe Coding Agent, enhanced by Compiler and Validation Feedback.@autobe is an AI agent for vibe coding that analyzes user requirements and automatically generates backend applications with the stack below. Since @autobe has been enhanced by TypeScript/Prisma compilers and OpenAPI validator feedback, it delivers 100% working code.\nTypeScript\nNestJS\nPrisma (Postgres)","playground#Playground":"","vibe-coding-ecosystem#Vibe Coding Ecosystem":"","full-stack-vibe-coding#Full Stack Vibe Coding":"Our WrtnLabs team is developing two more projects, @agentica and @autoview. @agentica automatically creates an AI Chatbot when you simply provide a swagger.json file, and @autoview automatically generates a Frontend Application when you provide a swagger.json file.Therefore, you're not limited to automatically creating a backend with @autobe and vibe coding. If you've created a backend server with vibe coding through @autobe, you can immediately create an AI Chatbot and Frontend Application alongside it.Can you converse? Then you're a full-stack developer.","agentica-ai-function-calling-framework#Agentica, AI Function Calling Framework":"@autobe is also developed using @agentica\nhttps://github.com/wrtnlabs/agenticaAgentica is an Agentic AI framework specialized in AI Function Calling.It does everything through function calling, and brings functions from the three protocols below. If you provide the swagger.json file of an @autobe generated backend server, it directly becomes an AI chatbot that interacts with it.\nTypeScript Class/Interface\nSwagger/OpenAPI Document\nMCP (Model Context Protocol) Server\nimport { Agentica, assertHttpController } from \"@agentica/core\";\nimport OpenAI from \"openai\";\nimport typia from \"typia\";\nimport { MobileFileSystem } from \"./services/MobileFileSystem\";\nconst agent = new Agentica({\n  vendor: {\n    api: new OpenAI({ apiKey: \"********\" }),\n    model: \"gpt-4o-mini\",\n  },\n  controllers: [\n    // functions from TypeScript class\n    typia.llm.controller<MobileFileSystem, \"chatgpt\">(\n      \"filesystem\",\n      MobileFileSystem(),\n    ),\n    // functions from Swagger/OpenAPI\n    assertHttpController({\n      name: \"shopping\",\n      model: \"chatgpt\",\n      document: await fetch(\n        \"https://shopping-be.wrtn.ai/editor/swagger.json\",\n      ).then(r => r.json()),\n      connection: {\n        host: \"https://shopping-be.wrtn.ai\",\n        headers: { Authorization: \"Bearer ********\" },\n      },\n    }),\n  ],\n});\nawait agent.conversate(\"I wanna buy MacBook Pro\");","autoview-type-to-react-component#AutoView, Type to React Component":"https://github.com/wrtnlabs/autoviewAutoView is a frontend automation tool that generates React component code from type information from the sources below. If you provide the swagger.json file of an @autobe generated backend server, it directly becomes a frontend application.\nTypeScript Type\nJSON Schema (OpenAPI Document)\nimport { AutoViewAgent } from \"@autoview/agent\";\nimport fs from \"fs\";\nimport OpenAI from \"openai\";\nimport typia, { tags } from \"typia\";\n// 1. Define your own TypeScript interface to display\ninterface IMember {\n  id: string & tags.Format<\"uuid\">;\n  name: string;\n  age: number & tags.Minimum<0> & tags.Maximum<100>;\n  thumbnail: string & tags.Format<\"uri\"> & tags.ContentMediaType;\n}\n// 2. Setup the AutoView agent\nconst agent = new AutoViewAgent({\n  model: \"chatgpt\",\n  vendor: {\n    api: new OpenAI({ apiKey: \"********\" }),\n    model: \"o3-mini\",\n    isThinkingEnabled: true,\n  },\n  input: {\n    type: \"json-schema\",\n    unit: typia.json.unit<IMember>(),\n  },\n  transformFunctionName: \"transformMember\",\n  experimentalAllInOne: true, // recommended for faster and less-error results\n});\n// 3. Get the result!\nconst result = await agent.generate(); \nawait fs.promises.writeFile(\n  \"./src/transformers/transformMember.ts\",\n  result.transformTsCode,\n  \"utf8\",\n);","roadmap-schedule#Roadmap Schedule":""}},"/docs/related/agentica":{"title":"Agentica","data":{}},"/docs/related/autoview":{"title":"Autoview","data":{}},"/docs/roadmap/alpha":{"title":"Alpha","data":{"alpha-pre-release#Alpha Pre-Release":"We are committed to delivering the best possible @autobe experience and have confirmed that all functional agents are operating correctly. Prior to our v1.0 official release, we plan to conduct two pre-release phases as outlined below.However, these alpha and beta pre-releases will lack certain refinements. Streaming functionality will not be available, which means users may experience longer wait times during conversations with the @autobe agent while it completes program generation. Additionally, limited event granularity may make it difficult to track the intermediate progress of functional agents.During this period, comprehensive documentation will not yet be available. Developers who wish to use @autobe at the library level may need to refer directly to API documentation, source code comments, or test programs to understand usage patterns.All these limitations will be resolved in the v1.0 official release.\nAlpha version: 2025-06-01","official-release#Official Release":"We will create a comprehensive technical specification website to introduce @autobe's concepts and usage. We'll provide detailed guidance on how to integrate @agentica with backend servers generated by @autobe to create AI chatbot applications, and how to leverage @autoview with @autobe generated servers to instantly build frontend and mobile applications.Additionally, we will implement streaming processing for @autobe agents, allowing users to observe in real-time what the @autobe agent is thinking, planning, and creating. We will enhance and document the event API to provide convenience for developers using @autobe at the library level.Once this comprehensive refinement work is completed, @autobe will be officially released as version 1.0. We appreciate your anticipation and support.\nTarget Release: 2025-09-01","hosting-service#Hosting Service":"We will create an integrated @autobe hosting service. When you discuss requirements with the @autobe agent through chat, your application will be deployed to our server infrastructure and made available for immediate use.This integrated hosting service will be connected with @agentica and @autoview. Simply by discussing requirements with the AI agent, you can automatically generate and deploy not only backend servers but also AI chatbot applications and frontend/mobile applications, all ready for immediate testing and use.While we cannot yet guarantee the exact launch date for our hosting service, Wrtn Technologies will demonstrate the future of vibe coding. We will show you not the current era's vibe coding where you might succeed once or twice out of 100 attempts and exclaim \"wow\" with excitement, but the future's vibe coding where 100 attempts yield 100 successes—truly reliable, production-ready automation.\nTarget Release: 2025-12-01"}},"/docs/roadmap/beta":{"title":"Roadmap > Beta Release (progress)","data":{"preface#Preface":"","1-analysis-agent#1. Analysis Agent":"","11-debate-enhancement#1.1. Debate Enhancement":"Enhance the debate functionality of the Analysis Agent to enable sophisticated requirement gathering through iterative dialogue.Previously, @autobe development focused primarily on Proof of Concept (PoC) and unit testing, so the Analysis Agent was validated with single utterances like \"I want to create a political/economic discussion board. Since I'm not familiar with programming, please write a requirements analysis report as you see fit.\"However, the Analysis Agent must be capable of conducting in-depth \"debates\" with AI agents regarding actual software development requirements. When users present requirements, the AI agent should analyze them, ask specific questions about ambiguous aspects, discover new elements through Q&A sessions, and pose deeper questions to perfectly specify requirements.This enhancement will include multi-turn conversation management for complex requirement gathering, enabling the system to maintain context across extended dialogues. The agent will employ intelligent questioning strategies to uncover hidden requirements that users may not initially express, while implementing contextual follow-up mechanisms to clarify ambiguous specifications. Through iterative refinement processes, the system will continuously validate requirements and document the evolution of requirements throughout the debate process, creating a comprehensive audit trail of how specifications develop and mature.","12-prefix-rule#1.2. Prefix Rule":"Extract project titles and common prefixes for tables/DTOs from the Analysis Agent to ensure consistent naming conventions across the entire backend architecture.The Analysis Agent creates requirement analysis documents and generates common prefixes for DB table and DTO definitions. For example, when given a project title like \"Shopping Mall,\" the Analysis Agent should generate a prefix like shopping, resulting in DB tables like shopping_cart_commodities and DTOs like ShoppingOrder.This system will implement automatic prefix generation based on project domain analysis, ensuring consistent naming convention enforcement across all generated artifacts. The system includes validation rules to ensure prefix compatibility with database and framework requirements, while providing conflict resolution mechanisms for complex multi-domain projects. When applicable, the system will integrate with existing codebase naming patterns to maintain consistency with legacy systems.","13-multimodal-support#1.3. Multimodal Support":"Verify whether requirements analysis documents properly reflect design artifacts from Figma and other sources received as images into actual functional designs.This involves developing comprehensive multimodal processing capabilities that can parse and interpret UI/UX designs from various image formats while extracting functional requirements from visual mockups and wireframes. The system will cross-reference design elements with textual requirements to identify inconsistencies between visual designs and written specifications, ultimately generating detailed API requirements based on UI component interactions.Additionally, verify whether requirements analysis documents generated through multimodal inputs properly propagate those multimodal assets to Prisma or Interface agents. If necessary, modify the history structure to ensure proper reflection of visual design elements throughout the entire development pipeline.","2-prisma-agent#2. Prisma Agent":"","21-compiler-development#2.1. Compiler Development":"Create a custom Prisma compiler to enable direct Prisma AST construction, validation, and code generation through function calling, replacing the current text-based approach with compilation error feedback.We initially attempted to have AI write Prisma schema files as text and provide feedback from official Prisma compiler errors. However, since Prisma compiler error messages are difficult even for humans to understand, AI correction based on compilation error messages proved ineffective.Our new Prisma compiler will define its AST as the AutoBePrisma.IApplication type, featuring detailed description comments at the level of AutoBeOpenApi.IDocument, enabling AI function calling to understand their meanings.The compiler will implement custom validation rules to prevent AI from designing incorrect Prisma schemas, detecting not only invalid syntax but also logically contradictory elements in otherwise compilable structures. It will provide comprehensive error reporting with actionable suggestions for AI correction while ensuring integration with existing Prisma ecosystem tools and workflows. Additionally, the system includes performance optimization for large-scale schema generation to handle complex enterprise applications efficiently.","22-prohibition-rule#2.2. Prohibition Rule":"Implement comprehensive validation rules in the custom Prisma compiler to prevent overly complex database designs and cross-dependencies that are difficult to implement in applications.While creating our custom Prisma compiler, we decided to add several prohibition clauses to the compiler validation rules. These rules will enforce:These rules will enforce circular dependency prevention by detecting and preventing circular references between database models that could lead to infinite loops or deadlocks. The system establishes complexity thresholds that limit the number of relationships per model to maintain manageable complexity while ensuring consistent naming patterns across all database entities. Performance optimization rules prevent schema designs that could lead to inefficient queries or poor database performance, while security constraint validation ensures that sensitive data relationships follow security best practices. Finally, scalability guidelines prevent designs that could become bottlenecks as the application scales to handle increased load and user growth.","23-sqlite-support#2.3. SQLite Support":"Implement comprehensive SQLite support in the custom Prisma compiler to enable playground website functionality and real-time validation of generated applications without external database dependencies.Currently, AutoBE's Prisma Agent exclusively targets PostgreSQL DBMS for schema design, creating significant operational limitations that impact both development workflows and user experience. The PostgreSQL dependency prevents the playground website from running generated applications directly in browser environments, as web-based platforms cannot host PostgreSQL servers. This limitation severely restricts the ability to demonstrate AutoBE's capabilities to potential users who want to experience end-to-end functionality without complex setup procedures.Additionally, AutoBE's own development and testing processes require PostgreSQL infrastructure setup, making it impossible to perform real-time validation of Test and Realize Agent outputs during development cycles. This dependency creates bottlenecks in the development workflow and prevents immediate verification of generated code functionality, forcing developers to rely on external database configurations that may not always be available or properly configured.To address these critical limitations, we will extend the custom Prisma compiler to support SQLite as a primary alternative database target, enabling seamless operation in constrained environments while maintaining full feature compatibility and business logic integrity.","3-interface-agent#3. Interface Agent":"","31-keyworded-sdk#3.1. Keyworded SDK":"Modify the client SDK library and e2e test functions generated from OpenAPI documents to use keyworded parameters instead of positional parameters for enhanced AI compatibility.@autobe uses AI function calling to compose Generative OpenAPI documents, converts them to regular OpenAPI documents, and generates NestJS projects. For each RESTful API endpoint, it creates SDK libraries for client convenience and ensures e2e test program compilation stability.The system currently uses the Nestia open-source project to generate NestJS projects and automatically create SDK and e2e test functions from OpenAPI documents. Since this project was created approximately 4 years ago, it uses human-oriented positional parameters rather than AI-oriented keyworded parameters.To resolve this, we will modify the Nestia code generator to generate keyworded parameters instead of positional parameters, allowing AI to call functions with enhanced flexibility and usability.\n// SDK and e2e test code generated with keyword options\nexport async function (\n  connection: api.IConnection,\n) {\n  const output: IShoppingSaleInquiryComment.ISnapshot =\n    await api.functional.shoppings.customers.sales.questions.comments.update(\n      connection,\n      {\n        saleId: typia.random<string & tags.Format<\"uuid\">>(),\n        inquiryId: typia.random<string & tags.Format<\"uuid\">>(),\n        id: typia.random<string & tags.Format<\"uuid\">>(),\n        body: typia.random<IShoppingSaleInquiryComment.ICreate>(),\n      },\n    );\n  typia.assert(output);\n}\n// Traditional approach with positional parameters\nexport async function (\n  connection: api.IConnection,\n) {\n  const output: IShoppingSaleInquiryComment.ISnapshot =\n    await api.functional.shoppings.customers.sales.questions.comments.update(\n      connection,\n      typia.random<string & tags.Format<\"uuid\">>(),\n      typia.random<string & tags.Format<\"uuid\">>(),\n      typia.random<string & tags.Format<\"uuid\">>(),\n      typia.random<IShoppingSaleInquiryComment.ICreate>(),\n    );\n  typia.assert(output);\n}","32-snapshot-logic#3.2. Snapshot Logic":"Implement comprehensive snapshot logic in the Interface Agent to ensure that OpenAPI documents and generated SDKs/e2e tests are properly validated against requirements analysis documents and Prisma DB schema definitions.","33-review-agent#3.3. Review Agent":"Develop a comprehensive review agent that verifies whether the OpenAPI document (API interface) written by AI properly follows the requirements analysis document and DB schema definition, identifying any missing or vague descriptions.This review agent will implement sophisticated validation mechanisms including requirements traceability to verify that every requirement from the analysis document is properly addressed in the API interface. The system ensures schema consistency by confirming that API endpoints align with the defined database schema and maintain referential integrity. Completeness validation identifies missing CRUD operations, authentication endpoints, and data validation rules, while documentation quality assessment evaluates the completeness and clarity of API documentation, including parameter descriptions, response schemas, and error handling. Security review verifies that appropriate authentication, authorization, and data validation mechanisms are implemented, and performance considerations assess API design for potential performance bottlenecks and suggest optimizations. Finally, standardization compliance ensures adherence to RESTful API design principles and OpenAPI specification standards.The agent will generate detailed reports highlighting discrepancies and providing actionable recommendations for improvement.","4-test-agent#4. Test Agent":"","41-scenario-agent#4.1. Scenario Agent":"An intelligent agent that creates comprehensive test scenarios from requirements analysis documents and API interfaces, providing detailed testing strategies for each endpoint.The Scenario Agent analyzes each API endpoint's e2e test function and its related assets (requirements analysis + API controller + DTO files) created by the Interface Agent. It performs dependency analysis to extract prerequisite endpoints needed to call target API endpoints and map their execution order. The agent generates comprehensive test cases including positive, negative, and edge case scenarios for complete testing coverage while mapping data flow to understand how information moves through the system and identify critical testing points. Integration scenario planning designs complex multi-endpoint test scenarios that simulate real-world usage patterns, and performance test scenarios generate load testing scenarios to validate system performance under various conditions. Security test cases create scenarios to test authentication, authorization, and data validation mechanisms throughout the application.The agent explains to the Coding Agent how to implement these scenarios, providing detailed step-by-step instructions and expected outcomes.","42-coding-agent#4.2. Coding Agent":"An advanced agent that reads scenarios from the Scenario Agent and creates actual executable e2e test code with comprehensive error handling and validation.The Coding Agent implements automated code generation to transform test scenarios into executable TypeScript/JavaScript test code while generating appropriate mocks for external dependencies and services. It implements comprehensive assertion logic to validate API responses and system behavior, creates and manages test data sets for various testing scenarios, and implements proper test cleanup to ensure test isolation and repeatability. Additionally, the agent integrates with reporting systems to generate detailed test reports with metrics and failure analysis.","43-compiler-feedback#4.3. Compiler Feedback":"interface ICorrectTestFunctionProps {\n  /**\n   * Step 1: Initial self-reflection on the source code without compiler error\n   * context.\n   *\n   * The AI agent analyzes the previously generated test code to identify\n   * potential issues, relying solely on its understanding of TypeScript syntax,\n   * testing patterns, and best practices.\n   *\n   * This encourages the agent to develop independent debugging skills before\n   * being influenced by external error messages.\n   */\n  think_without_compile_error: string;\n  /**\n   * Step 2: Re-evaluation of the code with compiler error messages as\n   * additional context.\n   *\n   * After the initial analysis, the AI agent reviews the same code again, this\n   * time incorporating the specific TypeScript compiler error messages.\n   *\n   * This allows the agent to correlate its initial observations with concrete\n   * compilation failures and refine its understanding of what went wrong.\n   */\n  think_again_with_compile_error: string;\n  /**\n   * Step 3: Concrete action plan for fixing the identified issues.\n   *\n   * Based on the analysis from steps 1 and 2, the AI agent formulates a\n   * specific, step-by-step solution strategy.\n   *\n   * This should include what changes need to be made, why those changes are\n   * necessary, and how they will resolve the compilation errors while\n   * maintaining the test's intended functionality.\n   */\n  solution: string;\n  /**\n   * Step 4: The corrected TypeScript test code.\n   *\n   * The final, properly fixed TypeScript code that should compile without\n   * errors.\n   *\n   * This represents the implementation of the solution plan from step 3,\n   * containing all necessary corrections to make the test code syntactically\n   * valid and functionally correct.\n   */\n  content: string;\n}\nAn intelligent agent that analyzes compilation errors from e2e test functions written by the Coding Agent and converts them to correct, functional code through structured output approach.This agent employs a structured output methodology to perform single-pass compilation error resolution, systematically analyzing TypeScript compilation errors and generating corrected code in a single operation. The approach leverages predefined output schemas to ensure consistent and comprehensive error analysis while providing immediate fixes for common compilation issues.When the structured output approach successfully resolves compilation problems, it eliminates the need for iterative debugging cycles, significantly improving the efficiency of the test code correction process.","44-function-calling#4.4. Function Calling":"interface IAutoBeTestCorrectApplication {\n  /**\n   * Step 1: Initial self-reflection and analysis of the test code without compiler error context.\n   * \n   * The AI agent performs an independent analysis of the provided test code, identifying\n   * potential issues based solely on TypeScript syntax knowledge, testing patterns, and\n   * best practices. This encourages the development of autonomous debugging capabilities\n   * before being influenced by external error messages.\n   */\n  thinkWithoutCompileError(p: {\n    /** AI's analysis and thoughts about potential issues in the code */\n    content: string;\n  }): void;\n  /**\n   * Step 2: Re-evaluation of the code incorporating compiler error messages.\n   * \n   * After the initial analysis, the AI agent reviews the same code again with the benefit\n   * of specific TypeScript compiler error messages. This allows correlation between the\n   * initial observations and concrete compilation failures, leading to a more informed\n   * understanding of the actual problems.\n   */\n  thinkAgainWithCompileError(p: {\n    /** AI's refined analysis incorporating compiler error information */\n    content: string;\n  }): void;\n  /**\n   * Step 3: Formulate and report the concrete solution strategy.\n   * \n   * Based on the analysis from steps 1 and 2, the AI agent creates a detailed action plan\n   * for fixing the identified issues. This should include specific changes to be made,\n   * rationale for each change, and how these modifications will resolve the compilation\n   * errors while preserving the test's intended functionality.\n   */\n  reportSolution(p: {\n    /** The solution plan and strategy description */\n    content: string;\n  }): void;\n  /**\n   * Step 4: Apply the corrections and return compilation results.\n   * \n   * Implements the solution plan by generating the corrected TypeScript code and\n   * immediately attempting compilation to verify the fixes. This provides immediate\n   * feedback on whether the corrections were successful or if further iteration is needed.\n   */\n  applyFixes(p: {\n    /** The corrected TypeScript test code */\n    content: string;\n  }): IAutoBeCompilerResult;\n  /**\n   * Step 5: Successfully complete the correction process.\n   * \n   * Signals that the test code has been successfully corrected and compiles without errors.\n   * This marks the end of the correction workflow and indicates that the AI agent has\n   * successfully resolved all identified issues.\n   */\n  complete(): void;\n  /**\n   * Emergency exit: Acknowledge inability to fix the current code.\n   * \n   * When the AI agent determines that the existing code cannot be repaired through\n   * incremental fixes and requires a complete rewrite, this function provides a graceful\n   * way to abort the current correction attempt. This prevents infinite loops of failed\n   * correction attempts and signals that a fresh approach is needed.\n   */\n  giveUp(): void;\n}\nWhen single-pass compiler feedback fails to resolve compilation bugs in e2e test programs written by the Test Agent, the system implements an advanced function calling strategy that defines the correction process as six specialized functions. This approach delegates the invocation and control of these functions entirely to AI function calling, enabling autonomous problem-solving capabilities that can handle complex compilation issues requiring multiple iterations and deep analysis.The correction workflow systematically guides the AI through a structured debugging process, from initial code analysis without external influence, through error-informed re-evaluation, to solution formulation and implementation. By entrusting the AI with complete control over when and how to invoke these correction functions, the system enables adaptive problem-solving that can dynamically adjust to different types of compilation challenges while maintaining the flexibility to abandon unsalvageable code when necessary.","45-compiler-development#4.5. Compiler Development":"Create a dedicated compiler for e2e test functions using the same methodology as the Prisma compiler, providing ultimate control over test code generation and validation.If AI-written e2e test function compilation bugs are still not resolved even with the function calling approach, this involves:\nCustom AST Structure: Create a dedicated Abstract Syntax Tree structure specifically designed for e2e test functions\nValidator Strategies: Establish comprehensive validation strategies that understand the unique requirements of e2e testing\nTypeScript Code Generator: Develop a sophisticated code generator that produces optimized, type-safe test code\nIntegration Framework: Ensure seamless integration with existing testing frameworks and CI/CD pipelines\nPerformance Optimization: Implement advanced optimization techniques for large-scale test suites\nHowever, since this approach requires significant development time, we prioritize resolution through compiler feedback and function calling strategies.","5-realization-agent#5. Realization Agent":"","51-planner-agent#5.1. Planner Agent":"An advanced agent that synthesizes all previous processes and writes comprehensive scenarios on how to create the main program for each API endpoint, including detailed technical specifications and implementation strategies.The Planner Agent performs architecture planning to design the overall architecture for each API endpoint implementation while selecting appropriate technologies and frameworks for optimal performance. It defines step-by-step implementation approaches for complex business logic and plans comprehensive error handling and recovery mechanisms. The agent designs security measures including authentication, authorization, and data validation, plans performance optimization strategies from the ground up, and ensures seamless integration with the testing framework developed by the Test Agent.","52-coding-agent#5.2. Coding Agent":"An expert-level agent that writes high-quality provider code for API endpoints based on scenarios from the Planner Agent, implementing industry best practices and optimal design patterns.The Coding Agent implements clean architecture principles for maintainable and scalable code while applying appropriate design patterns for different types of business logic. It implements comprehensive error handling with proper logging and monitoring, applies security best practices including input validation and output sanitization, and writes optimized code with consideration for scalability and efficiency. The agent also generates comprehensive inline documentation and API documentation to support long-term maintenance.","53-compiler-feedback#5.3. Compiler Feedback":"interface ICorrectRealizeFunctionProps {\n  /**\n   * Step 1: Initial self-reflection on the source code without compiler error\n   * context.\n   *\n   * The AI agent analyzes the previously generated realize code to identify\n   * potential issues, relying solely on its understanding of TypeScript syntax,\n   * coding patterns, and best practices.\n   *\n   * This encourages the agent to develop independent debugging skills before\n   * being influenced by external error messages.\n   */\n  think_without_compile_error: string;\n  /**\n   * Step 2: Re-evaluation of the code with compiler error messages as\n   * additional context.\n   *\n   * After the initial analysis, the AI agent reviews the same code again, this\n   * time incorporating the specific TypeScript compiler error messages.\n   *\n   * This allows the agent to correlate its initial observations with concrete\n   * compilation failures and refine its understanding of what went wrong.\n   */\n  think_again_with_compile_error: string;\n  /**\n   * Step 3: Concrete action plan for fixing the identified issues.\n   *\n   * Based on the analysis from steps 1 and 2, the AI agent formulates a\n   * specific, step-by-step solution strategy.\n   *\n   * This should include what changes need to be made, why those changes are\n   * necessary, and how they will resolve the compilation errors while\n   * maintaining the realize's intended functionality.\n   */\n  solution: string;\n  /**\n   * Step 4: The corrected TypeScript realize code.\n   *\n   * The final, properly fixed TypeScript code that should compile without\n   * errors.\n   *\n   * This represents the implementation of the solution plan from step 3,\n   * containing all necessary corrections to make the realize code syntactically\n   * valid and functionally correct.\n   */\n  content: string;\n}\nAn intelligent agent that analyzes and resolves compilation errors from the Coding Agent with advanced error resolution capabilities.This agent provides contextual error analysis to understand compilation errors within the broader context of the application architecture while implementing automatic fixes for common compilation issues. It suggests and implements code quality improvements during error resolution, resolves complex dependency issues and version conflicts, and ensures that error fixes don't negatively impact application performance through careful impact analysis.","54-function-calling#5.4. Function Calling":"interface IAutoBeRealizeCorrectApplication {\n  /**\n   * Step 1: Initial self-reflection and analysis of the realize code without compiler error context.\n   * \n   * The AI agent performs an independent analysis of the provided realize code, identifying\n   * potential issues based solely on TypeScript syntax knowledge, coding patterns, and\n   * best practices. This encourages the development of autonomous debugging capabilities\n   * before being influenced by external error messages.\n   */\n  thinkWithoutCompileError(p: {\n    /** AI's analysis and thoughts about potential issues in the code */\n    content: string;\n  }): void;\n  /**\n   * Step 2: Re-evaluation of the code incorporating compiler error messages.\n   * \n   * After the initial analysis, the AI agent reviews the same code again with the benefit\n   * of specific TypeScript compiler error messages. This allows correlation between the\n   * initial observations and concrete compilation failures, leading to a more informed\n   * understanding of the actual problems.\n   */\n  thinkAgainWithCompileError(p: {\n    /** AI's refined analysis incorporating compiler error information */\n    content: string;\n  }): void;\n  /**\n   * Step 3: Formulate and report the concrete solution strategy.\n   * \n   * Based on the analysis from steps 1 and 2, the AI agent creates a detailed action plan\n   * for fixing the identified issues. This should include specific changes to be made,\n   * rationale for each change, and how these modifications will resolve the compilation\n   * errors while preserving the realize's intended functionality.\n   */\n  reportSolution(p: {\n    /** The solution plan and strategy description */\n    content: string;\n  }): void;\n  /**\n   * Step 4: Apply the corrections and return compilation results.\n   * \n   * Implements the solution plan by generating the corrected TypeScript code and\n   * immediately attempting compilation to verify the fixes. This provides immediate\n   * feedback on whether the corrections were successful or if further iteration is needed.\n   */\n  applyFixes(p: {\n    /** The corrected TypeScript realize code */\n    content: string;\n  }): IAutoBeCompilerResult;\n  /**\n   * Step 5: Successfully complete the correction process.\n   * \n   * Signals that the realize code has been successfully corrected and compiles without errors.\n   * This marks the end of the correction workflow and indicates that the AI agent has\n   * successfully resolved all identified issues.\n   */\n  complete(): void;\n  /**\n   * Emergency exit: Acknowledge inability to fix the current code.\n   * \n   * When the AI agent determines that the existing code cannot be repaired through\n   * incremental fixes and requires a complete rewrite, this function provides a graceful\n   * way to abort the current correction attempt. This prevents infinite loops of failed\n   * correction attempts and signals that a fresh approach is needed.\n   */\n  giveUp(): void;\n}\nImplement the same advanced function calling strategy as the Test Agent for autonomous resolution of complex compilation issues.When compilation errors are not resolved through one-time compiler feedback, the system defines the correction process as 6 specialized functions with enhanced capabilities for production code:\nProduction Error Diagnosis: Specialized analysis for production-level code issues\nBusiness Logic Validation: Ensure that error fixes maintain business logic integrity\nSecurity Impact Assessment: Evaluate security implications of proposed fixes\nPerformance Impact Analysis: Assess performance implications of code changes\nProduction-Safe Implementation: Apply solutions with production-level safety measures\nComprehensive Validation: Perform thorough validation including integration testing","55-runtime-validation#5.5. Runtime Validation":"An advanced agent that runs comprehensive validation by executing e2e test programs created by the Test Agent on API provider code written by the Realization Agent.This agent ensures functional correctness by verifying that implemented APIs meet all functional requirements while ensuring that implementations meet performance benchmarks. It validates that security measures are properly implemented and effective, verifies proper integration between different system components, and ensures that error handling mechanisms work correctly under various failure scenarios. The agent also confirms that data integrity is maintained throughout all operations, providing comprehensive validation of the entire system.","6-enhancement#6. Enhancement":"","61-benchmark-testing#6.1. Benchmark Testing":"Develop a comprehensive performance measurement program that evaluates all agents comprising @autobe and generates detailed analytical reports.The benchmark system implements performance metrics collection to measure response times, accuracy rates, and resource utilization for each agent while conducting comparative analysis to compare performance across different scenarios and configurations. It tracks performance changes over time through regression testing to identify performance regressions and evaluates agent performance under various load conditions through scalability testing. The system measures code quality, test coverage, and documentation completeness as quality metrics and creates comprehensive markdown reports with visualizations and actionable insights through automated report generation.The system evaluates each agent using predefined histories for 10 specified scenarios, providing standardized performance benchmarks across all components.","62-demonstration#6.2. Demonstration":"Create comprehensive demonstration materials including repositories, videos, and community promotion to showcase @autobe capabilities.This includes repository creation to develop complete example projects showcasing different use cases, video production to create professional demonstration videos highlighting key features and capabilities, and community engagement to actively promote @autobe in developer communities and conferences. The initiative also develops interactive demonstrations that allow users to experience @autobe firsthand, providing tangible evidence of the platform's capabilities.Example demonstrations:\nhttps://www.youtube.com/watch?v=SIgP-1OcAwg\nhttps://stackblitz.com/github/wrtnlabs/autobe-example-bbs\nhttps://stackblitz.com/github/wrtnlabs/autobe-example-shopping","63-documentation#6.3. Documentation":"Create comprehensive guide documentation for @autobe following industry best practices and user-centric design principles.The documentation system will be similar in format to the official documentation of @agentica, Typia, and Nestia:\nhttps://wrtnlabs.io/agentica/\nhttps://typia.io/\nhttps://nestia.io/\nDocumentation components include getting started guides with step-by-step tutorials for new users, comprehensive API reference documentation with practical examples, and best practices guidelines for optimal @autobe usage. The documentation covers troubleshooting with common issues and their solutions, advanced topics providing in-depth coverage of complex features and customization options, and integration guides with instructions for incorporating @autobe into existing development workflows.","64-technical-articles#6.4. Technical Articles":"Develop a content strategy for regularly publishing technical articles that promote @autobe and establish thought leadership in the automated development space.Article topics include technical deep dives with detailed explanations of @autobe architecture and algorithms, case studies featuring real-world examples of successful @autobe implementations, and industry analysis providing insights into the future of automated software development. The content strategy encompasses best practices guides for maximizing @autobe effectiveness and community contributions highlighting community projects and collaborative efforts.","65-review-agent#6.5. Review Agent":"Implement review agents for each component that evaluate outputs and derive improvement points to enhance overall system quality.For example, the API Interface Review Agent conducts requirements compliance reviews to ensure whether outputs properly reflect requirements analysis documents while ensuring schema consistency and alignment with Prisma DB schema definitions. It performs completeness assessment to identify missing or poorly described elements and provides quality improvement feedback to help interface agents enhance their output quality.This qualitative feedback system operates differently from compiler feedback, focusing on semantic correctness and completeness rather than syntactic issues.","66-system-maintenance#6.6. System Maintenance":"Implement a comprehensive maintenance strategy to ensure continuous improvement and optimal performance of the entire @autobe system.Although the 3-month roadmap focuses on PoC development, the final month includes a dedicated maintenance period to conduct comprehensive system review of the entire development process and architecture. This period focuses on quality enhancement to identify and address areas requiring improvement or strengthening while optimizing system performance and resource utilization. The maintenance phase ensures documentation updates remain current and accurate, addresses any identified issues or edge cases through systematic bug fixes, and finalizes the system for production deployment through thorough preparation procedures.","7-ecosystem#7. Ecosystem":"","71-agentica-prerequisites#7.1. @agentica Prerequisites":"Enhance the @agentica function calling framework to properly identify and manage prerequisite function relationships for complex automation scenarios.@agentica is a function calling framework that requires enhancement to properly identify relationships between prerequisite functions while orchestrating execution by making appropriate preliminary calls in the correct sequence. The framework needs improved error handling to manage failures in prerequisite functions gracefully, performance optimization to optimize execution order for better efficiency, and a comprehensive validation framework to implement thorough validation for function call chains.This enhancement is critical for function calling strategies utilized in compiler feedback correction in Test and Realization agents.","72-websocket-streaming#7.2. WebSocket Streaming":"Implement comprehensive WebSocket streaming support for real-time communication and progress updates during @autobe operations.Currently, @agentica and @autobe support streaming for text responses from AI agents. However, when served through WebSocket, streaming is not yet supported, and content is delivered as one-time JSON responses.The implementation includes real-time progress updates to stream progress information for long-running operations while delivering incremental results as they become available. The system provides error streaming with real-time error information and recovery suggestions, robust connection management with automatic reconnection capabilities, and scalability to support multiple concurrent streaming connections efficiently.Since @autobe operations require substantial time for each agent, proper streaming support is essential for user experience.","73-history-manipulation#7.3. History Manipulation":"Develop sophisticated history manipulation capabilities to allow users to start @autobe processes from intermediate states or with existing artifacts.This addresses scenarios like: \"I already have an ERD. Can you create interfaces and test programs starting from here?\"The system implements reverse engineering capabilities to derive requirements analysis documents from existing ERDs or schemas while reconstructing @autobe agent history from existing artifacts. It manages complex state transitions between different starting points, ensures consistency when starting from intermediate states through comprehensive validation, and seamlessly integrates with existing development workflows to provide flexibility in project initiation.","74-ai-chatbot-development#7.4. AI Chatbot Development":"Extend @autobe capabilities to automatically generate AI chatbots from developed backend services, making advanced AI integration accessible to non-technical users.Currently, it's possible to serve backend servers developed with @autobe through @agentica to create AI chatbots, but this requires development expertise. The enhancement makes this accessible to anyone by providing automatic integration to generate code that serves @agentica and converts backends to AI chatbots. The system includes configuration management with user-friendly configuration interfaces, deployment automation to automate the deployment process for generated chatbots, monitoring and analytics capabilities for operational insights, and customization options that allow users to tailor chatbot behavior and appearance to their specific needs.","75-data-seeder-agent#7.5. Data Seeder Agent":"Develop an intelligent data seeding agent that uses AI chatbot technology to help users populate their applications with meaningful initial data.One critical aspect of backend applications is initial data seeding. For example, a shopping mall created with @autobe has no value without products. The Data Seeder Agent addresses this by providing intelligent data generation to create contextually appropriate seed data based on application domain while enabling interactive seeding by converting the backend server into an AI chatbot using @agentica for user interaction. The system guides users through the data seeding process via conversational interface, ensures seeded data meets application requirements and constraints through comprehensive data validation, supports efficient bulk data operations for large datasets, and provides a template library with pre-built data templates for common application types."}},"/docs/roadmap/v1.0":{"title":"AutoBE v1.0 Official Release Roadmap","data":{"official-release#Official Release":"AutoBE v1.0 represents a fundamental shift from proof-of-concept to production-ready automation that transforms how digital services are created. This official release establishes AutoBE as the foundation for a complete no-coding ecosystem where anyone can build, deploy, and operate sophisticated applications through simple conversation.Our vision extends beyond generating working code to creating a comprehensive platform where business ideas become reality within minutes. The v1.0 release, targeted for December 1, 2025, focuses on three core pillars: business-ready backend generation that supports real commercial operations, seamless integration with our no-coding ecosystem that eliminates technical barriers, and a hosting service that instantly transforms conversations into deployed applications.We envision a world where the ability to articulate an idea becomes the only prerequisite for digital entrepreneurship. Whether it's a grandmother in rural Korea opening an online marketplace or a small business owner automating customer management, AutoBE v1.0 will democratize access to sophisticated technology infrastructure that was previously available only to well-funded enterprises.","production-ready-business-applications#Production-Ready Business Applications":"A 70-year-old grandmother who grows tomatoes in the countryside created an online debate website in just 10 minutes. This grandmother, who is unfamiliar with both coding and computers, completed a current affairs and economics debate community simply by conversing with Wrtn's AI. What's remarkable is that this site allows both writing and commenting entirely through voice. Users can even engage in current affairs debates with AI.The next day, the grandmother invested another 20 minutes to open an agricultural products shopping mall. Customers simply say \"I'd like to order 2kg of tomatoes\" and the order is completed, while the grandmother manages everything from orders and shipping to inventory through simple chat.\nThis story isn't science fiction—it represents the transformative potential of AutoBE v1.0. The rural grandmother's achievement demonstrates how AutoBE eliminates the traditional barriers between business ideas and digital implementation, enabling anyone with entrepreneurial vision to create sophisticated, commercially viable applications regardless of their technical background.AutoBE v1.0 transforms from a development tool into a business enablement platform. The official release focuses on generating backend systems that can handle real commercial traffic, process actual transactions, and support growing businesses from day one.The production readiness encompasses comprehensive security implementations including enterprise-grade authentication, authorization, and data protection mechanisms. Performance optimization ensures that generated applications can scale from initial launch to thousands of concurrent users without architectural changes. Database design incorporates production best practices including proper indexing, query optimization, and data integrity constraints that maintain reliability under real-world load.Business logic implementation reaches commercial sophistication, handling complex scenarios like inventory management, payment processing, customer relationship management, and regulatory compliance. Error handling and logging provide the operational visibility necessary for business-critical applications, while automated backup and recovery mechanisms protect against data loss.These applications handle real customer interactions, process genuine transactions, and operate at business scale from the moment of creation, making stories like the rural grandmother's digital entrepreneurship journey an accessible reality for anyone.","no-coding-ecosystem#No Coding Ecosystem":"AutoBE v1.0 serves as the cornerstone of a revolutionary no-coding ecosystem that eliminates the traditional boundaries between business ideas and digital implementation. The integration of AutoBE, Agentica, and AutoView creates a seamless pipeline from concept to fully operational digital business.The ecosystem operates on a simple yet powerful principle: if you can describe what you want, you can build it. AutoBE generates the backend infrastructure that powers your business logic, handles data management, and provides secure API endpoints. Agentica transforms this backend into an intelligent AI assistant that can interact naturally with customers, process orders, answer questions, and handle routine business operations. AutoView completes the picture by automatically generating user interfaces that customers and business owners can use across web and mobile platforms.This integrated approach eliminates the traditional handoffs between different development phases. Instead of requiring separate teams for backend development, AI integration, and frontend creation, the entire stack emerges from a single conversation. The grandmother's agricultural marketplace demonstrates this seamlessly: one conversation with AutoBE created the product catalog and order management system, Agentica enabled voice-based ordering and customer service, and AutoView generated both the customer shopping interface and the admin dashboard for inventory management.The ecosystem's intelligence extends beyond individual tools to understand the relationships between different components. When AutoBE designs an e-commerce backend, Agentica automatically understands the business context to provide relevant customer service, while AutoView generates interfaces that match the specific domain requirements. This contextual awareness ensures that the generated applications feel purpose-built rather than generic.Business owners focus entirely on their domain expertise—understanding customers, refining products, and growing their market—while the technical infrastructure adapts automatically to support their evolving needs. The ecosystem handles scaling challenges, security updates, and feature enhancements through the same conversational interface used for initial creation.","hosting-service#Hosting Service":"The AutoBE Hosting Service represents the culmination of our no-coding vision: a platform where conversations instantly become deployed, operational applications accessible to real users. This service eliminates the final barrier between idea and implementation by handling all infrastructure, deployment, and operational concerns automatically.When users complete their conversation with AutoBE, the system doesn't just generate code—it immediately provisions cloud infrastructure, deploys the application, configures security settings, and makes the service available through a custom domain. The backend API starts handling requests within minutes of conversation completion, with automatic scaling, monitoring, and backup systems already in place.The integration with Agentica transforms every AutoBE-generated backend into an intelligent AI assistant accessible through web interfaces, mobile apps, or even phone calls. Customers can interact with businesses using natural language, while the AI handles order processing, customer service, appointment scheduling, and routine inquiries. Business owners manage their operations through the same conversational interface, asking questions like \"How many orders did we receive today?\" or \"Schedule a promotional campaign for next week.\"AutoView integration generates customer-facing applications and administrative dashboards that are immediately live and functional. The shopping mall created through AutoBE conversation becomes a fully operational e-commerce site with product catalogs, shopping carts, payment processing, and order tracking—all accessible through web browsers and mobile devices within minutes of the initial conversation.The hosting service includes comprehensive business support features: payment gateway integration for immediate monetization, analytics dashboards for business insights, customer communication tools for engagement, and automated marketing capabilities for growth. Domain management, SSL certificates, and compliance configurations are handled automatically, allowing business owners to focus entirely on serving their customers.Our ultimate vision is a world where anyone with a business idea can immediately test it in the market. Instead of months of planning, development, and deployment, entrepreneurs can validate concepts, serve real customers, and iterate based on actual feedback within the same day they conceive their idea. The hosting service transforms AutoBE from a development tool into a complete business platform that democratizes digital entrepreneurship.Digital business creation becomes as simple as having a conversation. Whether it's a local restaurant wanting online ordering, a consultant needing client management tools, or an artist seeking to sell their work online, the AutoBE Hosting Service instantly transforms ideas into operational businesses ready to serve customers and generate revenue."}},"/docs/setup":{"title":"Setup","data":{"playground#Playground":"","local-setup#Local Setup":"git clone https://github.com/wrtnlabs/autobe\ncd autobe\npnpm install\npnpm run playground\nYou can setup playground like application on your local machine.Clone this @autobe repository and run the playground script after installing dependencies with pnpm install. This will start a local server that you can access to interact with the @autobe agent.","websocket-server#WebSocket Server":"import { AutoBeAgent } from \"@autobe/agent\";\nimport { AutoBePlaygroundServer }  from \"@autobe/playground-server\";\nimport { AutoBeCompiler } from \"@autobe/compiler\";\nimport OpenAI from \"openai\";\nconst server = new AutoBePlaygroundServer({\n  predicate: async (acceptor) => {\n    return {\n      type: \"accept\",\n      agent: new AutoBeAgent({\n        vendor: {\n          api: new OpenAI({ apiKey: \"********\" }),\n          model: \"gpt-4.1\",\n        },\n        model: \"chatgpt\",\n        compiler: new AutoBeCompiler(),\n      }),\n      cwd: `${__dirname}/../playground-result`,\n    }\n  },\n});\nawait server.listen(3_000);\nYou can serve the @autobe agent as a WebSocket server like above.About detailed information, please refer to the Guide Documents > WebSocket Protocol page."}},"/docs/websocket/client":{"title":"Client","data":{}},"/docs/websocket":{"title":"Index","data":{"autoberpc#@autobe/rpc":"","setup#Setup":"","nestjs-server#NestJS Server":"","nodejs-server#NodeJS Server":"","client-application#Client Application":"","remote-procedure-call#Remote Procedure Call":"WebSocket protocol with RPC paradigm for AI chatbot.","header#Header":"Header value delivered from client to server after the connection.In TGrid's RPC (Remote Procedure Call) paradigm, header means a value that is delivered after the connection from a client to the server. And header is used in most cases to authenticate the connecting client.In the above example project, IAuthorizationHeader is the header type, and is used by server to determine whether to accept the client's connection or not. If the client's header is not valid, the server would reject the connection.","provider#Provider":"Functions provided from remote system.Provider is an object instance containing some functions provided for the remote system for RPC (Remote Procedure Call). In many cases, the provide becomes a class instance containing some methods to be called, but it is okay that composing the provider by just an interface type.Also, the opposite remote system will call provider's functions by the Driver<Remote> instance. In the above example, client application is providing IAgenticaRpcListener to the server, and server is providing AgenticaRpcService (IAgenticaRpcService) to the client.","driver#Driver":"Driver of RPC (Remote Procedure Call).Driver is a proxy instance designed to call functions of the remote system. It has a generic argument Remote which means the type of remote system's Provider, and you can remotely call the functions of the Provider asynchronously through the Drive<Remote> instance.When you call some function of remote Provider by the Driver<Listener> instance, it hooks the function call expression, and delivers the function name and arguments (parameter values) to the remote system through the Communicator. If the remote system succeeded to reply the result of the function call, Communicator resolves the promise of the function call expression with the result, so that makes Driver<Remote> working.In the above example, client application is calling IAgenticaRpcService.conversate() function remotely through the Driver<IAgenticaRpcService> typed instance. In that case, IAgenticaRpcService is the Provider instance from server to client."}},"/docs/websocket/nestjs":{"title":"Nestjs","data":{}},"/docs/websocket/nodejs":{"title":"Nodejs","data":{}},"/":{"title":"Index","data":{"introduction#Introduction":"Guide Documents · Playground (Online IDE) · Github Repository\nBackend Vibe Coding Agent, enhanced by Compiler and Validation Feedback.@autobe is an AI agent for vibe coding that analyzes user requirements and automatically generates backend applications with the stack below. Since @autobe has been enhanced by TypeScript/Prisma compilers and OpenAPI validator feedback, it delivers 100% working code.\nTypeScript\nNestJS\nPrisma (Postgres)","playground#Playground":""}},"/docs/concepts/compiler":{"title":"Guide Documents > Concepts > Compiler","data":{"outline#Outline":"AutoBE revolutionizes backend development through a sophisticated three-tier compiler infrastructure that transforms natural language requirements into production-ready applications. This vibe coding ecosystem operates on the fundamental principle that conversations should directly generate working software, eliminating the traditional barriers between human intent and machine implementation.The compiler architecture consists of three specialized components working in perfect harmony: AutoBE's custom Prisma Compiler for database schema generation, AutoBE's custom OpenAPI Compiler for API specification and interface generation, and the official TypeScript Compiler for final code validation. Each compiler operates on structured Abstract Syntax Tree (AST) data through AI function calling, ensuring 100% syntactic correctness while maintaining semantic integrity throughout the development pipeline.This three-tier architecture operates on the revolutionary principle of \"structure first, validate continuously, generate deterministically.\" Unlike traditional development where errors emerge during coding and testing phases, AutoBE's compiler infrastructure prevents errors at the structural level, ensuring that every generated application works correctly on the first attempt.The vibe coding approach transforms the entire software development lifecycle. Conversations with users become structured requirements, requirements become validated AST structures, AST structures become production-ready code, and production-ready code becomes deployable applications—all without manual intervention or debugging cycles.","prisma-compiler#Prisma Compiler":"AutoBE's custom Prisma Compiler represents the foundational layer of the vibe coding infrastructure, transforming business requirements into validated database architectures through sophisticated AST manipulation. This compiler operates exclusively on AutoBePrisma.IApplication structures, eliminating the error-prone nature of text-based schema authoring while ensuring perfect consistency between business logic and data storage design.","vibe-coding-database-architecture#Vibe Coding Database Architecture":"The Prisma Compiler processes structured data through comprehensive AutoBePrisma.IApplication interfaces that capture every aspect of database design as typed, validated structures. AI agents construct these ASTs through function calling, ensuring that database schemas are semantically correct and business-aligned before any code generation occurs.\ninterface AutoBePrisma.IApplication {\n  files: IFile[];\n}\ninterface IFile {\n  filename: string & tags.Pattern<\"^[a-zA-Z0-9._-]+\\\\.prisma$\">;\n  namespace: string;\n  models: IModel[];\n}\ninterface IModel {\n  name: string & tags.Pattern<\"^[a-z][a-z0-9_]*$\">;\n  description: string;\n  material: boolean;\n  primaryField: IPrimaryField;\n  foreignFields: IForeignField[];\n  plainFields: IPlainField[];\n  uniqueIndexes: IUniqueIndex[];\n  plainIndexes: IPlainIndex[];\n  ginIndexes: IGinIndex[];\n}\nThis structured approach fundamentally eliminates the possibility of syntactic errors in database design. Every property is typed, constrained, and validated to ensure that only valid database architectures can be constructed. The function calling interface prevents invalid combinations at the source, creating a development environment where database design errors simply cannot occur.","advanced-semantic-validation#Advanced Semantic Validation":"The AutoBE Prisma Compiler implements multi-layered validation logic that operates on complete AST structures, catching design flaws and business logic inconsistencies before any code generation occurs. This validation system understands not just syntax but the semantic relationships that make databases functionally effective.Relationship Graph Analysis: The compiler constructs comprehensive relationship graphs from AST data to detect circular dependencies, orphaned entities, and invalid cardinality constraints. This analysis ensures that database designs will function correctly under all operational conditions, preventing the subtle relationship errors that often plague traditional database development.Business Logic Validation: Custom validation rules ensure that AST structures properly represent business requirements, checking constraints like mandatory audit fields, proper naming conventions, and adherence to domain-specific patterns. The compiler validates that every business rule expressed in requirements analysis is properly reflected in the database design.Performance Optimization Analysis: The system evaluates query patterns implicit in AST structures to identify potential performance bottlenecks before they become problems. It validates that appropriate indexes are defined for common access patterns and warns against designs that could lead to poor query performance at scale.Security Constraint Enforcement: The compiler ensures that sensitive data relationships follow security best practices, validating that access patterns align with security requirements and that proper constraints are in place to prevent unauthorized data access.","intelligent-error-prevention-system#Intelligent Error Prevention System":"Unlike traditional compilers that report errors after code generation, the AutoBE Prisma Compiler prevents errors at the AST construction level through sophisticated guidance systems that help AI agents make optimal design decisions.Real-Time Validation Feedback: When AI agents attempt to construct invalid AST structures, the function calling system provides immediate, contextual feedback with specific guidance on how to correct issues. This creates a continuous learning loop that improves database design quality in real-time.Contextual Design Suggestions: Error messages include not just identification of problems but specific suggestions for valid alternatives that achieve the same business goals. For example, if an AI attempts to create a problematic relationship pattern, the system suggests alternative design patterns that maintain business functionality while avoiding technical issues.Progressive Validation Architecture: The AST can be built incrementally with validation occurring at each step, allowing AI agents to construct complex database schemas piece by piece while maintaining validity throughout the process. This progressive approach enables the development of sophisticated database architectures without overwhelming complexity.","deterministic-code-generation-pipeline#Deterministic Code Generation Pipeline":"Once AST validation succeeds, the Prisma Compiler transforms structured data into production-ready Prisma schema files through a deterministic generation process that produces consistent, high-quality output every time.Comprehensive Documentation Synthesis: The compiler automatically generates detailed documentation from AST descriptions, ensuring that every model and field includes extensive explanations of their business purpose, technical constraints, and operational characteristics. This documentation becomes an integral part of the codebase, providing ongoing value for maintenance and enhancement.Automatic Index Optimization: Based on relationship patterns and access patterns defined in the AST, the compiler automatically generates optimal database indexes for common query scenarios. This eliminates the need for manual performance tuning while ensuring that generated databases perform effectively under realistic load conditions.Constraint Generation and Enforcement: All business rules and validation logic defined in the AST are automatically translated into appropriate database constraints, ensuring data integrity at the storage level. This includes foreign key constraints, check constraints, and unique constraints that enforce business rules directly in the database.ERD Integration and Visualization: The compiler seamlessly integrates with prisma-markdown to generate Entity Relationship Diagrams that accurately reflect AST structures. These diagrams provide visual documentation that stays perfectly synchronized with implementation, enabling better communication between technical and business stakeholders.","openapi-compiler#OpenAPI Compiler":"AutoBE's custom OpenAPI Compiler bridges the critical gap between database design and application implementation, transforming validated AST structures into comprehensive API specifications and complete NestJS applications. This compiler operates on the same vibe coding principles as the Prisma Compiler, ensuring that API designs are syntactically perfect and semantically aligned with business requirements before any code generation occurs.","ast-driven-api-architecture#AST-Driven API Architecture":"The OpenAPI Compiler works exclusively with AutoBeOpenApi.IDocument AST structures that AI agents construct through function calling, eliminating the possibility of creating invalid or incomplete API specifications. This approach ensures that every API endpoint is thoroughly planned, properly documented, and correctly integrated with the underlying database architecture.\ninterface AutoBeOpenApi.IDocument {\n  operations: AutoBeOpenApi.IOperation[];\n  components: AutoBeOpenApi.IComponents;\n}\ninterface AutoBeOpenApi.IOperation {\n  specification: string;\n  description: string;\n  summary: string;\n  path: string;\n  method: \"get\" | \"post\" | \"put\" | \"delete\" | \"patch\";\n  parameters: AutoBeOpenApi.IParameter[];\n  requestBody: AutoBeOpenApi.IRequestBody | null;\n  responseBody: AutoBeOpenApi.IResponseBody | null;\n}\nThe AST structure enforces critical design principles at the construction level, requiring every operation to include detailed specifications that articulate business purpose before defining technical implementation. This constraint ensures that API designs are thoroughly understood and properly planned before code generation begins.Multi-paragraph descriptions are required for every operation, covering different aspects such as business purpose, security considerations, data relationships, and integration requirements. This structured approach to documentation ensures that generated APIs are self-documenting and provide comprehensive guidance for both developers and automated systems.","comprehensive-business-logic-integration#Comprehensive Business Logic Integration":"The OpenAPI Compiler implements sophisticated validation and integration logic that ensures perfect alignment between API specifications and business requirements while maintaining consistency with database designs generated by the Prisma Compiler.Prisma Schema Synchronization: The compiler validates that every table defined in the Prisma schema has corresponding API operations, ensuring complete coverage of the data model through the API layer. This validation prevents incomplete API implementations and maintains perfect consistency between database capabilities and API surface area.Business Rule Enforcement: The system validates that API operations properly implement business rules and constraints defined in requirements specifications, ensuring that the API design accurately reflects business needs and operational requirements. This includes validation of data flow patterns, access control requirements, and business process implementations.Type Safety Bridge Maintenance: Cross-references between database schemas and API type definitions are continuously validated to ensure referential integrity throughout the application stack. The compiler ensures that changes to database structures are properly reflected in API interfaces and that type constraints are consistently enforced.Security Pattern Validation: The compiler ensures that appropriate authentication and authorization patterns are consistently applied across all operations that require security controls, validating that security requirements defined in business analysis are properly implemented in the API design.","multi-stage-transformation-excellence#Multi-Stage Transformation Excellence":"The OpenAPI Compiler operates through a sophisticated transformation pipeline that converts AST structures into multiple output formats while maintaining perfect semantic consistency and ensuring industry standard compliance.AST to OpenAPI Transformation: The first transformation stage converts AutoBeOpenApi.IDocument AST into standard OpenApi.IDocument format, expanding simplified type references into complete OpenAPI schema definitions while preserving all semantic meaning and business context.Industry Standard Validation: The generated OpenAPI document undergoes comprehensive validation against OpenAPI 3.1 specification standards, ensuring complete industry compliance and compatibility with the broader OpenAPI tooling ecosystem. This validation includes structural verification, cross-reference validation, and specification conformance checking.Enhanced NestJS Generation: The validated OpenAPI document feeds into AutoBE's enhanced code generation pipeline, producing complete NestJS projects with controllers, DTOs, client SDKs, and comprehensive testing frameworks. This generation process includes AutoBE's innovative enhancements designed specifically for vibe coding workflows.","revolutionary-code-generation-enhancements#Revolutionary Code Generation Enhancements":"AutoBE's OpenAPI Compiler includes several groundbreaking enhancements designed specifically for vibe coding workflows and AI-optimized development patterns that significantly improve both AI usability and human developer experience.Keyworded Parameter Innovation: Unlike traditional code generators that produce positional parameters optimized for human developers, AutoBE generates client SDK functions with keyworded parameters specifically optimized for AI consumption while simultaneously improving human readability and reducing integration errors.\n// AutoBE Enhanced Generation (AI & Human Optimized)\nawait api.functional.shoppings.customers.orders.comments.update(\n  connection,\n  {\n    customerId: \"550e8400-e29b-41d4-a716-446655440000\",\n    orderId: \"550e8400-e29b-41d4-a716-446655440001\",\n    commentId: \"550e8400-e29b-41d4-a716-446655440002\",\n    updateData: commentUpdateInfo\n  }\n);\n// Traditional Positional Approach\nawait api.functional.shoppings.customers.orders.comments.update(\n  connection,\n  \"550e8400-e29b-41d4-a716-446655440000\",\n  \"550e8400-e29b-41d4-a716-446655440001\", \n  \"550e8400-e29b-41d4-a716-446655440002\",\n  commentUpdateInfo\n);\nComprehensive Documentation Integration: Generated code includes rich JSDoc documentation derived directly from AST descriptions, ensuring that implementation code maintains the same level of documentation quality as the specification. This documentation includes business context, usage examples, and integration guidance that helps both human developers and AI systems understand proper usage patterns.Intelligent Test Scaffold Generation: Every API operation receives automatically generated test scaffolds that understand dependency relationships between operations and include business logic validation beyond simple request/response verification. These scaffolds provide the foundation for comprehensive testing that validates both technical functionality and business rule implementation.End-to-End Type Safety Assurance: Generated TypeScript interfaces maintain perfect alignment with Prisma schemas and OpenAPI specifications, ensuring complete type safety throughout the entire application stack from database queries to client interactions.","real-time-validation-and-feedback#Real-Time Validation and Feedback":"The OpenAPI Compiler provides immediate, intelligent feedback during AST construction, enabling rapid iteration and continuous improvement of API designs through sophisticated validation systems designed specifically for AI interaction patterns.Contextual Structural Validation: Real-time validation ensures that AST structures are properly formed and contain all required elements before proceeding to transformation stages. This validation includes completeness checking, consistency verification, and pattern conformance validation.Cross-Component Consistency Checking: The compiler continuously validates consistency between operations, parameters, schemas, and business rules to ensure that API designs are internally coherent and follow established patterns throughout the specification.Business Logic Compliance Verification: The system validates that API operations properly implement business rules and constraints defined in requirements specifications and Prisma schemas, ensuring that technical implementation accurately reflects business intentions.Performance and Scalability Analysis: The compiler analyzes API designs for potential performance issues and suggests optimizations based on established best practices, helping ensure that generated applications will perform effectively under realistic operational conditions.","typescript-compiler#TypeScript Compiler":"AutoBE leverages the official TypeScript Compiler as the final validation and quality assurance layer in its vibe coding pipeline, ensuring that all generated code meets production standards and integrates seamlessly with the broader TypeScript ecosystem. While AutoBE's AST-based approach eliminates most potential errors before code generation, the TypeScript Compiler serves as the ultimate quality gate that validates perfect integration between generated components and framework requirements.","production-ready-code-validation#Production-Ready Code Validation":"The TypeScript Compiler integration provides comprehensive validation that ensures generated code is not only syntactically correct but also semantically sound within the broader application context and ready for immediate deployment in production environments.Framework Integration Verification: The compiler validates that generated NestJS controllers, DTOs, and service providers correctly integrate with framework APIs and follow established architectural patterns. This validation ensures that AST-generated code works seamlessly with manually written code when customization or extension is required.Type System Integrity Validation: Generated TypeScript interfaces and types undergo rigorous validation for correctness within the TypeScript type system, ensuring that complex type relationships derived from AST structures maintain their intended semantics throughout the compilation process. This includes validation of generic type parameters, conditional types, and mapped types used in advanced API patterns.Dependency Resolution and Module Consistency: The compiler verifies that all generated modules correctly resolve their dependencies and that the modular structure derived from AST organization translates correctly to TypeScript module systems. This validation ensures that generated applications have clean, maintainable module architectures.Build System and Toolchain Compatibility: Final compilation ensures that generated code integrates properly with standard TypeScript build toolchains, enabling seamless deployment through existing CI/CD pipelines and development workflows without requiring special build configuration or custom tooling.","advanced-error-detection-and-analysis#Advanced Error Detection and Analysis":"While AutoBE's AST-based approach prevents most errors from occurring, the TypeScript Compiler provides sophisticated error detection for edge cases and complex interactions that might arise from the integration of multiple generated components or framework-specific requirements.Cross-Module Integration Analysis: The compiler validates that types and interfaces generated from different AST components maintain consistency when used together, catching potential integration issues that might not be apparent at the individual AST level. This includes validation of data flow between controllers, services, and data access layers.Framework API Compliance Verification: Generated code is validated against actual framework APIs to ensure that AST-derived implementations correctly use NestJS decorators, Prisma client APIs, and other external dependencies. This validation catches API usage errors that could occur due to framework version changes or configuration differences.Runtime Type Safety Assurance: The compiler verifies that generated code maintains type safety even when dealing with runtime data transformation and validation, ensuring that AST-defined constraints translate correctly to runtime validation logic implemented through libraries like Typia.Complex Business Logic Validation: For generated service implementations, the compiler validates that business logic implementations properly handle all error conditions, maintain transactional integrity, and correctly implement the business rules defined in the original requirements and AST structures.","comprehensive-development-workflow-support#Comprehensive Development Workflow Support":"The TypeScript Compiler integration ensures that AutoBE-generated applications provide the same high-quality development experience as traditionally authored TypeScript applications while maintaining the advantages of automated generation.IDE Integration Excellence: Generated code passes full TypeScript compilation with comprehensive type information, enabling complete IDE support including intelligent autocomplete, real-time error detection, sophisticated refactoring capabilities, and comprehensive navigation features that help developers understand and maintain generated applications.Advanced Toolchain Compatibility: Compiled code integrates seamlessly with the entire TypeScript development ecosystem including advanced linters like ESLint, code formatters like Prettier, bundlers like Webpack and Vite, and testing frameworks like Jest and Vitest, ensuring that generated applications fit naturally into existing development workflows.Incremental Development and Maintenance: The compiler supports incremental builds and development workflows that allow developers to iterate on generated applications, add custom business logic, and extend functionality without losing the benefits of AutoBE's vibe coding approach. This includes support for partial regeneration and selective updates.Debugging and Observability Support: Generated code includes proper source map generation, debugging symbols, and observability hooks that enable effective troubleshooting and performance monitoring in both development and production environments.","quality-assurance-and-production-readiness#Quality Assurance and Production Readiness":"The TypeScript Compiler serves as the final checkpoint ensuring that all generated code meets the highest standards for production deployment while maintaining the consistency and reliability advantages of automated generation.Performance Optimization Validation: The compiler's optimization analysis ensures that generated code will perform effectively in production environments, identifying any potential performance issues introduced during AST-to-code transformation and suggesting optimizations where appropriate.Security Compliance Verification: Type system validation helps ensure that security constraints defined in AST structures are properly enforced in the generated implementation, maintaining security guarantees throughout the entire transformation pipeline from requirements to production code.Deployment Readiness Assurance: Final compilation validates that generated applications can be successfully deployed using standard TypeScript deployment processes, ensuring seamless integration with existing infrastructure, containerization systems, and cloud deployment platforms.Long-term Maintainability Validation: The compiler ensures that generated code follows TypeScript best practices and established conventions, making it maintainable by development teams even after initial generation. This includes validation of code organization, naming patterns, and architectural consistency that supports long-term software lifecycle management.Regeneration Compatibility: The validation process ensures that applications can be safely regenerated when requirements change, maintaining compatibility with any custom extensions or modifications while preserving the benefits of automated development through AutoBE's vibe coding approach.The TypeScript Compiler integration completes AutoBE's revolutionary vibe coding infrastructure by ensuring that the sophistication and reliability of AST-based generation translates into production-ready applications that meet the same standards as traditionally developed TypeScript applications, while maintaining the speed, consistency, and quality advantages that make AutoBE's approach transformational for modern software development."}},"/docs/concepts/waterfall":{"title":"Guide Documents > Concepts > Waterfall","data":{"outline#Outline":"@autobe is based on the waterfall model but incorporates the spiral model's iterative improvement cycles, producing high-quality code through continuous feedback between users and AI.The spiral process ensures not only well-structured code but also safe and reliable implementations verified by integrated TypeScript/Prisma compilers, OpenAPI validator, and automated test programs at each development stage.\nWaterfall\tAutoBE\tDescription\tRequirements\tAnalze\tDebate requirements with user.\tAnalysis\tAnalze\tWrite requirement analysis reports.\tDesign\tPrisma\tWrite prisma schema (DB ORM) files and draw ERD.\tDesign\tInterface\tWrite OpenAPI document, convert it to a NestJS project.\tDevelopment\tRealize\tWrite implementation code for each API endpoint.\tTesting\tTest\tWrite e2e test functions for each API endpoint.\tMaintenance\t*\tUsers can request AutoBE to modify the backend application.","analyze-agent#Analyze Agent":"An agent that analyzes requirements and creates specification documents.\nInput: All conversation history between users and AI\nOutput: Structured requirements specification\nFeatures:\nSeparates business logic from technical requirements\nGenerates follow-up questions for ambiguous requirements\nEstablishes priorities and defines development scope\nThe Analyze agent serves as the foundation of the entire development process. It not only captures initial requirements but also continuously refines understanding through iterative conversation with users. When requirements are ambiguous or incomplete, it proactively formulates targeted questions to elicit necessary information before proceeding with development.Additionally, once other agents have generated code, the Analyze agent can interpret change requests in the context of existing implementations, assessing the impact and feasibility of modifications while maintaining system integrity. This comprehensive approach ensures that all subsequent development stages work from a clear, complete, and consistent specification.","prisma-agent#Prisma Agent":"An agent that generates database schemas through AutoBE's specialized AST-based approach.\nInput: Requirements specification\nOutput: Prisma DB schema and ERD documentation\nFeatures:\nNo-code approach using AutoBePrisma.IApplication AST structure\nBuilt-in AutoBE Prisma compiler for validation and code generation\nAutomatic ERD documentation generation (using prisma-markdown)\nSchema optimization through self-review system\nThe Prisma agent implements AutoBE's no-code methodology by working with structured data rather than text files. Instead of writing Prisma schema code directly, the AI constructs AutoBePrisma.IApplication AST (Abstract Syntax Tree) data through function calling. This approach eliminates syntax errors and ensures consistency by operating at a higher abstraction level.The workflow begins with analyzing the requirements specification to understand the data model needs. The AI then uses function calling to build the AutoBePrisma.IApplication AST, which represents the complete database structure including entities, relationships, attributes, and constraints in a validated format.AutoBE's built-in Prisma compiler validates this AST for correctness, consistency, and adherence to database design best practices. When validation errors occur, they're immediately fed back to the AI, enabling rapid iteration and refinement. This creates a feedback loop that continuously improves the schema design without manual debugging.Once validation passes, the compiler automatically generates the actual Prisma schema files from the AST. The generated schemas include comprehensive documentation for each entity and attribute, explaining their business purpose and relationships. Finally, ERD documentation is produced using prisma-markdown, and the entire output undergoes quality review to ensure it meets project standards.\n/// Final component information on units for sale.\n/// \n/// `shopping_sale_snapshot_unit_stocks` is a subsidiary entity of \n/// {@link shopping_sale_snapshot_units} that represents a product catalog \n/// for sale, and is a kind of final stock that is constructed by selecting \n/// all {@link shopping_sale_snapshot_unit_options options} \n/// (variable \"select\" type) and their \n/// {@link shopping_sale_snapshot_unit_option_candidates candidate} values in \n/// the belonging unit. It is the \"good\" itself that customers actually \n/// purchase.\n/// \n/// - Product Name) MacBook\n///   - Options\n///   - CPU: { i3, i5, i7, i9 }\n///   - RAM: { 8GB, 16GB, 32GB, 64GB, 96GB }\n///   - SSD: { 256GB, 512GB, 1TB }\n///   - Number of final stocks: 4 * 5 * 3 = 60\n///\n/// For reference, the total number of `shopping_sale_snapshot_unit_stocks` \n/// records in an attribution unit can be obtained using Cartesian Product. \n/// In other words, the value obtained by multiplying all the candidate \n/// values that each (variable \"select\" type) option can have by the number \n/// of cases is the total number of final stocks in the unit. \n///\n/// Of course, without a single variable \"select\" type option, the final \n/// stocks count in the unit is only 1.\n///\n/// @namespace Sales\n/// @erd Carts\nmodel shopping_sale_snapshot_unit_stocks {\n  /// Primary Key.\n  ///\n  /// @format uuid\n  id String @id @db.Uuid\n  /// Belonged unit's {@link shopping_sale_snapshot_units.id}\n  ///\n  /// @format uuid\n  shopping_sale_snapshot_unit_id String @db.Uuid\n  /// Name of the final stock.\n  name String @db.VarChar\n  /// Nominal price.\n  ///\n  /// This is not real price to pay, but just a nominal price to show.\n  /// If this value is greater than the `real_price`, it would be shown\n  /// like seller is giving a discount.\n  ///\n  /// @minimum 0\n  nominal_price Float @db.DoublePrecision\n  /// Real price to pay.\n  ///\n  /// @minimum 0\n  real_price Float @db.DoublePrecision\n  /// Initial inventory quantity.\n  ///\n  /// If this stock has been sold over this quantity count, the stock can't\n  /// be sold anymore, because of out of stock. In that case, the seller can\n  /// supplement the inventory quantity by registering some \n  /// {@link shopping_sale_snapshot_unit_stock_supplements} records.\n  ///\n  /// @minimum 0\n  quantity Int\n  /// Sequence order in belonged unit.\n  sequence Int @db.Integer\n}","interface-agent#Interface Agent":"An agent that designs API interfaces through AutoBE's specialized AST-based approach.\nInput: Requirements specification, ERD documentation\nOutput:\nOpenAPI Document generated from AST\nComplete NestJS project with TypeScript code\nTypeScript DTO types\nNestJS Controllers\nClient SDK Library\nE2E Test Functions\nFeatures:\nNo-code approach using AutoBeOpenApi.IDocument AST structure\nBuilt-in AutoBE API design compiler for validation and transformation\nMulti-stage transformation pipeline (AST → OpenAPI → NestJS)\nComprehensive API documentation generation\nThe Interface agent employs AutoBE's no-code methodology to create precise, validated API interfaces. Rather than writing OpenAPI documents or TypeScript code manually, the AI constructs AutoBeOpenApi.IDocument AST structures through function calling - a specialized, streamlined format optimized for AutoBE's development workflow.The process starts with comprehensive analysis of the requirements specification and ERD documentation to understand business needs and data relationships. Using function calling, the AI builds the AutoBeOpenApi.IDocument AST that captures the complete API design including endpoints, request/response schemas, validation rules, and documentation.This custom AST format provides a more constrained and validated structure compared to raw OpenAPI or TypeScript, helping maintain consistency and preventing design flaws that could arise from unrestricted flexibility. The structured approach ensures that all APIs follow established patterns and conventions.AutoBE's built-in API design compiler validates the AST structure for correctness, consistency, and best practices. The validation covers HTTP method usage, naming conventions, status codes, and documentation completeness. Any validation errors trigger feedback to the AI for immediate correction, creating an iterative refinement process.The transformation pipeline operates in two distinct stages. First, the AutoBeOpenApi.IDocument AST is converted into a standard OpenApi.IDocument format that conforms to the official OpenAPI specification. This OpenAPI document undergoes additional specification-compliant validation. Second, the validated OpenAPI document feeds into AutoBE's code generation pipeline, producing the complete NestJS project including controllers, DTOs, client SDK library, and E2E test scaffolds.Each generated interface includes comprehensive JSDoc documentation explaining its purpose, behavior, and relationships. An internal review process continuously validates the generated interfaces against the original requirements and data model, ensuring completeness and consistency throughout the development cycle.","test-agent#Test Agent":"An agent that enhances and completes E2E test code for each API interface.\nInput: API interfaces, OpenAPI Schema, pre-generated E2E test scaffolds\nOutput: Complete test code for each API function\nFeatures:\nEnhancement of automatically generated test scaffolds\nDependency analysis for proper test sequencing\nComplex scenario generation with business logic validation\nComprehensive test documentation\nTypeScript compiler validation\nTest coverage optimization\nThe Test agent builds sophisticated test suites from the foundation provided by the Interface agent's automatically generated E2E test scaffolds. When the Interface agent transforms AutoBeOpenApi.IDocument AST into a NestJS project, it mechanically creates basic test function scaffolds for each API endpoint. The Test agent's role is transforming these skeletal structures into comprehensive, business-aware test suites.Working with the pre-generated scaffolds alongside requirements specifications, ERD documentation, and API interfaces, the Test agent develops sophisticated test scenarios that validate individual endpoint functionality and business rule compliance. It analyzes cross-endpoint interactions to ensure comprehensive system validation.A key capability is dependency analysis between API functions. When endpoints require preconditions established by other API calls, the agent structures integrated test scenarios with proper execution sequencing. This dependency-aware approach ensures tests reflect real-world usage patterns and catch integration issues.The agent designs comprehensive test scenarios covering edge cases, error conditions, and complex business workflows. Each enhanced test includes detailed documentation explaining the test's purpose, prerequisites, expected outcomes, and relationship to business requirements, serving as both executable validation and living documentation.Built-in TypeScript compiler validation provides immediate feedback on syntax and type correctness. Compilation errors trigger iterative refinement, creating a self-correcting development loop. An internal review process evaluates test coverage and quality, ensuring optimal validation thoroughness across the entire API surface.\nimport { TestValidator } from \"@nestia/e2e\";\nimport api from \"@ORGANIZATION/PROJECT-api\";\nimport { IBbsArticle } from \"@ORGANIZATION/PROJECT-api/lib/structures/IBbsArticle\";\nimport { IBbsArticleComment } from \"@ORGANIZATION/PROJECT-api/lib/structures/IBbsArticleComment\";\nimport typia from \"typia\";\nexport async function (connection: api.IConnection): Promise<void> {\n  // 1. Create an article to comment on\n  const articleInput: IBbsArticle.ICreate = {\n    writer: \"employee_special\",\n    format: \"txt\",\n    title: \"Test Article for Special Comment\",\n    body: \"This is a base article for comment posting.\",\n    files: [],\n    password: \"secure_pw1!\"\n  };\n  const article = await api.functional.bbs.articles.post(connection, {\n    body: articleInput,\n  });\n  typia.assert<IBbsArticle>(article);\n  \n  // 2. Post a comment with special characters, emojis, and multilingual text\n  const specialCommentBody =\n    \"Greetings! 👋 こんにちは！💡 Ça va? Привет! مرحبا! 你好！ & <script>alert('XSS')</script> \\n -- السلام عليكم -- 𝄞✨\";\n  const commentInput: IBbsArticleComment.ICreate = {\n    writer: \"employee_special\",\n    format: \"txt\",\n    body: specialCommentBody,\n    files: [],\n    password: \"special_comment_pw1@\"\n  };\n  const comment = await api.functional.bbs.articles.comments.postByArticleid(connection, {\n    articleId: article.id,\n    body: commentInput,\n  });\n  typia.assert<IBbsArticleComment>(comment);\n  \n  // 3. Retrieve the comment and validate its content\n  const commentId = comment.id;\n  const readComment = await api.functional.bbs.articles.comments.getByArticleidAndId(connection, {\n    articleId: article.id,\n    id: commentId,\n  });\n  typia.assert<IBbsArticleComment>(readComment);\n  TestValidator.equals(\"comment writer\")(\n    comment.writer\n  )(readComment.writer);\n  TestValidator.equals(\"special comment body\")(\n    comment.snapshots[0].body\n  )(specialCommentBody);\n  \n  // 4. (Negative/robustness) Try posting an empty body (should be rejected or stored as empty)\n  const invalidCommentInput: IBbsArticleComment.ICreate = {\n    writer: \"employee_special\",\n    format: \"txt\",\n    body: \"\",\n    files: [],\n    password: \"special_comment_pw2@\"\n  };\n  await TestValidator.error(\"should reject empty body\")(\n    () => api.functional.bbs.articles.comments.postByArticleid(connection, {\n      articleId: article.id,\n      body: invalidCommentInput,\n    })\n  );\n}","realize-agent#Realize Agent":"An agent that implements complete service logic for each API function.\nInput: Requirements specification, Prisma schema, API interfaces, enhanced test code\nOutput: Complete service implementation code for each API endpoint\nFeatures:\nDirect TypeScript implementation (traditional coding approach)\nDual feedback validation (compilation + runtime testing)\nBusiness logic implementation with best practices\nDatabase integration through Prisma\nComprehensive error handling and security\nThe Realize agent represents the culmination of the AutoBE development pipeline, synthesizing all previous agents' outputs to create fully functional service implementations. Unlike other agents that use AST-based no-code approaches, the Realize agent employs traditional coding methods to write actual TypeScript implementation code.The implementation process begins with comprehensive analysis of all available artifacts. The requirements specification defines business logic requirements, the Prisma schema provides the data model, the OpenAPI document specifies API contracts, and the enhanced test code establishes validation criteria. This multi-source analysis ensures implementations satisfy all defined requirements and constraints.The agent creates maintainable, efficient code that correctly implements business logic while following established best practices. Generated service providers handle database interactions through Prisma, implement security and validation checks, process business rules according to specifications, and ensure proper error handling and logging.A robust dual-feedback validation system ensures high-quality output. The embedded TypeScript compiler provides immediate compilation feedback, catching syntax errors and type mismatches. More critically, implementation code undergoes continuous testing against the Test Agent's enhanced test suites, providing runtime validation of functional correctness and business logic compliance.This compile-time and runtime validation creates a comprehensive quality assurance environment where errors are caught and corrected iteratively. An internal review process evaluates code quality, identifying optimization opportunities, performance improvements, and coding standard adherence. The result is implementation code that is functionally correct, maintainable, and performant."}}}